{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from db_utils import RDSDatabaseConnector\n",
    "from data_extraction import DataExtractor\n",
    "from data_transformer import DataTransformer\n",
    "from data_frame_info import DataFrameInfo\n",
    "\n",
    "current_directory = os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by first extracting our data from an RDS database \n",
    "Ensure you have a yaml_file initialised with the correct credentials to access the RDS Database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the credentials file\n",
    "yaml_file = \"credentials.yaml\"\n",
    "\n",
    "# Initialize the database connector\n",
    "db_connector = RDSDatabaseConnector(yaml_file)\n",
    "\n",
    "\n",
    "# Initialize the data extractor with the database connector's engine\n",
    "data_extractor = DataExtractor(db_connector.engine)\n",
    "\n",
    "# Task 3 Step 6: Extract data from the 'customer_activity' table\n",
    "table_name = \"customer_activity\"\n",
    "data = data_extractor.read_rds_table(table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our db_connector utilizes the credentials from the YAML file to initialize a SQLAlchemy engine for database connections. \n",
    "This engine is passed to our data_extractor, enabling it to retrieve the customer activity data. \n",
    "\n",
    "We save this data into a CSV file on our local machine to avoid repeatedly connecting to the database, thereby accelerating our exploratory data analysis process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = os.path.join(current_directory, 'customer_activity.csv')\n",
    "data_extractor.save_to_csv(data, csv_file_path) # Saving data to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step will be to load the data onto our panda dataframe, and to gather information on the nature of our dataset\n",
    "so we can decide what the best way to clean/transform it is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   administrative            11760 non-null  float64\n",
      " 1   administrative_duration   11418 non-null  float64\n",
      " 2   informational             12330 non-null  int64  \n",
      " 3   informational_duration    11994 non-null  float64\n",
      " 4   product_related           11751 non-null  float64\n",
      " 5   product_related_duration  12129 non-null  float64\n",
      " 6   bounce_rates              12330 non-null  float64\n",
      " 7   exit_rates                12330 non-null  float64\n",
      " 8   page_values               12330 non-null  float64\n",
      " 9   month                     12330 non-null  object \n",
      " 10  operating_systems         12319 non-null  object \n",
      " 11  browser                   12330 non-null  object \n",
      " 12  region                    12330 non-null  object \n",
      " 13  traffic_type              12330 non-null  object \n",
      " 14  visitor_type              12330 non-null  object \n",
      " 15  weekend                   12330 non-null  bool   \n",
      " 16  revenue                   12330 non-null  bool   \n",
      "dtypes: bool(2), float64(8), int64(1), object(6)\n",
      "memory usage: 1.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>administrative</th>\n",
       "      <th>administrative_duration</th>\n",
       "      <th>informational</th>\n",
       "      <th>informational_duration</th>\n",
       "      <th>product_related</th>\n",
       "      <th>product_related_duration</th>\n",
       "      <th>bounce_rates</th>\n",
       "      <th>exit_rates</th>\n",
       "      <th>page_values</th>\n",
       "      <th>month</th>\n",
       "      <th>operating_systems</th>\n",
       "      <th>browser</th>\n",
       "      <th>region</th>\n",
       "      <th>traffic_type</th>\n",
       "      <th>visitor_type</th>\n",
       "      <th>weekend</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>Android</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>North America</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>876.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Nov</td>\n",
       "      <td>Windows</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Google search</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>368.0</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sep</td>\n",
       "      <td>Windows</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1432.0</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.028</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Dec</td>\n",
       "      <td>Windows</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>Instagram ads</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>694.0</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>May</td>\n",
       "      <td>Android</td>\n",
       "      <td>Google Chrome</td>\n",
       "      <td>North America</td>\n",
       "      <td>Instagram ads</td>\n",
       "      <td>Returning_Visitor</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   administrative  administrative_duration  informational  \\\n",
       "0             0.0                      0.0              0   \n",
       "1             0.0                      0.0              0   \n",
       "2             2.0                     99.4              0   \n",
       "3             0.0                      0.0              0   \n",
       "4             0.0                      0.0              0   \n",
       "\n",
       "   informational_duration  product_related  product_related_duration  \\\n",
       "0                     0.0              4.0                       0.0   \n",
       "1                     0.0             26.0                     876.0   \n",
       "2                     0.0             19.0                     368.0   \n",
       "3                     0.0             20.0                    1432.0   \n",
       "4                     0.0             33.0                     694.0   \n",
       "\n",
       "   bounce_rates  exit_rates  page_values month operating_systems  \\\n",
       "0        0.2000       0.200          0.0   May           Android   \n",
       "1        0.0000       0.026          0.0   Nov           Windows   \n",
       "2        0.0396       0.052          0.0   Sep           Windows   \n",
       "3        0.0248       0.028          1.8   Dec           Windows   \n",
       "4        0.0141       0.032          0.0   May           Android   \n",
       "\n",
       "         browser          region   traffic_type       visitor_type  weekend  \\\n",
       "0  Google Chrome   North America        Twitter  Returning_Visitor    False   \n",
       "1  Google Chrome  Western Europe  Google search  Returning_Visitor     True   \n",
       "2  Google Chrome            Asia        Twitter  Returning_Visitor    False   \n",
       "3  Google Chrome  Western Europe  Instagram ads  Returning_Visitor    False   \n",
       "4  Google Chrome   North America  Instagram ads  Returning_Visitor    False   \n",
       "\n",
       "   revenue  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3     True  \n",
       "4    False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading our data onto a dataframe\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description\n",
    "\n",
    "The dataset consists of 17 columns with various data types and contains 12,330 entries. Below is a brief description of each column:\n",
    "\n",
    "- **administrative**: Number of administrative pages visited by the user.\n",
    "- **administrative_duration**: Duration spent on administrative pages.\n",
    "- **informational**: Number of informational pages visited by the user.\n",
    "- **informational_duration**: Duration spent on informational pages.\n",
    "- **product_related**: Number of product-related pages visited by the user.\n",
    "- **product_related_duration**: Duration spent on product-related pages.\n",
    "- **bounce_rates**: Percentage of visitors who enter the site and then leave (\"bounce\") rather than continuing to view other pages within the same site.\n",
    "- **exit_rates**: Percentage of pageviews on the site that were the last in the session.\n",
    "- **page_values**: Metrics assigned to a page to quantify its economic value.\n",
    "- **month**: Month of the year when the activity was recorded.\n",
    "- **operating_systems**: Type of operating system used by the visitor.\n",
    "- **browser**: Type of browser used by the visitor.\n",
    "- **region**: Geographical region of the visitor.\n",
    "- **traffic_type**: Source of the traffic, such as search engines or social media.\n",
    "- **visitor_type**: Whether the visitor is new or returning.\n",
    "- **weekend**: Whether the activity was recorded on a weekend.\n",
    "- **revenue**: Whether the visit resulted in a transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our analysis we can see that we have various columns which dont have their data_types initilised, they are in \"object\" format. From the title of these columns they appear to be categorical, before converting it we will take a closer look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "month                10\n",
       "operating_systems     7\n",
       "browser              13\n",
       "region                9\n",
       "traffic_type         19\n",
       "visitor_type          3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_info = DataFrameInfo(df)\n",
    "# print(df['month'].unique())\n",
    "# print(df['region'].unique())\n",
    "# print(df['traffic_type'].unique())\n",
    "# print(df['visitor_type'].unique())\n",
    "# print(df['browser'].unqiue())\n",
    "print(\"Number of distinct values in each column:\")\n",
    "df[['month','operating_systems', 'browser', 'region', 'traffic_type', 'visitor_type']].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our assumption is correct, they all have limited unique values, meaning it would make sense to change the column to categorical data type. This will not only conserve memory but allow us to do specialised analysis later on if we deem necessary. We will use our DataTransformer class, a class we created in 'data_transformer.py' to handle this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12330 entries, 0 to 12329\n",
      "Data columns (total 17 columns):\n",
      " #   Column                    Non-Null Count  Dtype   \n",
      "---  ------                    --------------  -----   \n",
      " 0   administrative            11760 non-null  float64 \n",
      " 1   administrative_duration   11418 non-null  float64 \n",
      " 2   informational             12330 non-null  int64   \n",
      " 3   informational_duration    11994 non-null  float64 \n",
      " 4   product_related           11751 non-null  float64 \n",
      " 5   product_related_duration  12129 non-null  float64 \n",
      " 6   bounce_rates              12330 non-null  float64 \n",
      " 7   exit_rates                12330 non-null  float64 \n",
      " 8   page_values               12330 non-null  float64 \n",
      " 9   month                     12330 non-null  category\n",
      " 10  operating_systems         12319 non-null  category\n",
      " 11  browser                   12330 non-null  category\n",
      " 12  region                    12330 non-null  category\n",
      " 13  traffic_type              12330 non-null  category\n",
      " 14  visitor_type              12330 non-null  category\n",
      " 15  weekend                   12330 non-null  bool    \n",
      " 16  revenue                   12330 non-null  bool    \n",
      "dtypes: bool(2), category(6), float64(8), int64(1)\n",
      "memory usage: 966.0 KB\n"
     ]
    }
   ],
   "source": [
    "data_transformer = DataTransformer(df)\n",
    "df = data_transformer.convert_columns(['month','operating_systems', 'browser', 'region', 'traffic_type', 'visitor_type'], dtype='category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step will be to  take a closer look at our null values and decide how to handle it.\n",
    "In the data_frame_info.py I have creaeted a clas with various methods to retrieve information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "administrative              4.622871\n",
       "administrative_duration     7.396594\n",
       "informational               0.000000\n",
       "informational_duration      2.725061\n",
       "product_related             4.695864\n",
       "product_related_duration    1.630170\n",
       "bounce_rates                0.000000\n",
       "exit_rates                  0.000000\n",
       "page_values                 0.000000\n",
       "month                       0.000000\n",
       "operating_systems           0.089213\n",
       "browser                     0.000000\n",
       "region                      0.000000\n",
       "traffic_type                0.000000\n",
       "visitor_type                0.000000\n",
       "weekend                     0.000000\n",
       "revenue                     0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preforming further inspection\n",
    "df_info = DataFrameInfo(df)\n",
    "df_info.null_percentage()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "\n",
    "The columns with the missing values are:\n",
    "\n",
    "- **administrative**: 4.62% missing\n",
    "- **administrative_duration**: 7.40% missing\n",
    "- **product_related**: 4.70% missing\n",
    "- **informational_duration**: 2.73% missing\n",
    "- **product_related_duration**: 1.630170\n",
    "- **operating_systems**: 0.089213%\n",
    "\n",
    "#### Addressing Missing Data\n",
    "\n",
    "We have several options for handling missing data:\n",
    "\n",
    "1. **Drop the rows or columns with missing values.**\n",
    "2. **Replace the missing values with statistical measures such as the mean, mode, or median.**\n",
    "3. **Apply advanced imputation methods like K-Nearest Neighbors (KNN).**\n",
    "\n",
    "#### Missing Data Mechanisms\n",
    "\n",
    "Before proceeding, it is important to determine if our missing data is Missing Completely At Random (MCAR) or Not Missing At Random (NMAR).\n",
    "\n",
    "- **MCAR**: The missingness is independent of any observed or unobserved data. This means the missing data does not depend on other values in the dataset. For instance, if the missing values in `informational_duration` were randomly distributed, it would be considered MCAR. This type of missing data introduces little to no bias.\n",
    "\n",
    "- **NMAR**: The missingness depends on unobserved data. For example, if users who spend very short or very long times on administrative pages are more likely to have missing values in `administrative_duration`, then the data is NMAR. This tpye of misisng data can introduce significant bias and will require advanced stastistical techniques to address.\n",
    "\n",
    "#### Example from Our Dataset\n",
    "\n",
    "Consider the `administrative_duration` column, which has 7.40% missing values. If these missing values are NMAR, it could be due to technical issues such as session timeouts for long durations. If we ignore this and impute using the mean or median, we risk skewing our results. \n",
    "\n",
    "For example, if users who spend longer on administrative pages are not recorded, we might incorrectly conclude that shorter page durations are more effective for user engagement and generating revenue. This could lead us to reduce the amount of content on administrative pages, potentially harming the user experience and negatively impacting business outcomes. \n",
    "\n",
    "### Next Step\n",
    "\n",
    "We wil run a stastistical test to see if our msising data is **MCAR** or **NMAR**\n",
    "\n",
    "A more detailed analysis, such as examining correlations between `administrative_duration` and other variables, followed by statistical tests, can help determine the nature of the missingness. If the missingness is related to the values, we would need to employ more sophisticated imputation methods or account for the missingness in our modeling process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9495907221356985\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyampute.exploration.mcar_statistical_tests import MCARTest\n",
    "\n",
    "# Load the dataset\n",
    "data_mcar = pd.read_csv(\"customer_activity.csv\")\n",
    "\n",
    "# Select the specified column - Must be numerical types.\n",
    "specified_columns = data_mcar[['administrative', 'administrative_duration', 'product_related', 'informational_duration', 'exit_rates', 'product_related_duration', 'page_values', 'bounce_rates', 'informational']]\n",
    "\n",
    "# Apply the Little's MCAR test to the specified columns\n",
    "mt = MCARTest(method=\"little\")\n",
    "print(mt.little_mcar_test(specified_columns))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for Missing Completely At Random (MCAR)\n",
    "\n",
    "We will be running Little's MCAR test to determine if the missing data in our dataset is missing completely at random.\n",
    "\n",
    "**Null Hypothesis (H0):** The data is missing completely at random (MCAR).\n",
    "\n",
    "**Alternative Hypothesis (H1):** The data is not missing completely at random (not MCAR).\n",
    "\n",
    "We will use a p-value to determine the result of the test:\n",
    "- If the p-value is greater than the significance level (commonly 0.05), we fail to reject the null hypothesis, indicating the data is MCAR.\n",
    "- If the p-value is less than or equal to the significance level, we reject the null hypothesis, indicating the data is not MCAR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Little's MCAR test result: 0.9495907221356985\n",
      "Not enough evidence to reject the null hypothesis. The data is MCAR.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pyampute.exploration.mcar_statistical_tests import MCARTest\n",
    "\n",
    "# Load the dataset\n",
    "data_mcar = pd.read_csv(\"customer_activity.csv\")\n",
    "\n",
    "# Select the specified columns - must be numerical types\n",
    "specified_columns = data_mcar[['administrative', 'administrative_duration', 'product_related', 'informational_duration', 'exit_rates', 'product_related_duration', 'page_values', 'bounce_rates', 'informational']]\n",
    "\n",
    "# Apply the Little's MCAR test to the specified columns\n",
    "mt = MCARTest(method=\"little\")\n",
    "test_result = mt.little_mcar_test(specified_columns)\n",
    "\n",
    "# Print the test result and determine the outcome\n",
    "print(\"Little's MCAR test result:\", test_result)\n",
    "p_value = test_result\n",
    "if p_value > 0.05:\n",
    "    print(\"Not enough evidence to reject the null hypothesis. The data is MCAR.\")\n",
    "else:\n",
    "    print(\"Reject the null hypothesis. The data is not MCAR.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_transformer.impute_null(['administrative'], 'mode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_transformer.remove_null(['administrative_duration'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_remove_null = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
